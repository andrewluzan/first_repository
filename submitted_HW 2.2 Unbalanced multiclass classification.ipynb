{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUPArbcFJKzJ"
   },
   "source": [
    "У цьому ДЗ ми потренуємось розв'язувати задачу багатокласової класифікації за допомогою логістичної регресії з використанням стратегій One-vs-Rest та One-vs-One, оцінити якість моделей та порівняти стратегії."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7f4tzX6YomVv"
   },
   "source": [
    "### Опис задачі і даних\n",
    "\n",
    "**Контекст**\n",
    "\n",
    "В цьому ДЗ ми працюємо з даними про сегментацію клієнтів.\n",
    "\n",
    "Сегментація клієнтів – це практика поділу бази клієнтів на групи індивідів, які схожі між собою за певними критеріями, що мають значення для маркетингу, такими як вік, стать, інтереси та звички у витратах.\n",
    "\n",
    "Компанії, які використовують сегментацію клієнтів, виходять з того, що кожен клієнт є унікальним і що їхні маркетингові зусилля будуть більш ефективними, якщо вони орієнтуватимуться на конкретні, менші групи зі зверненнями, які ці споживачі вважатимуть доречними та які спонукатимуть їх до купівлі. Компанії також сподіваються отримати глибше розуміння уподобань та потреб своїх клієнтів з метою виявлення того, що кожен сегмент цінує найбільше, щоб точніше адаптувати маркетингові матеріали до цього сегменту.\n",
    "\n",
    "**Зміст**.\n",
    "\n",
    "Автомобільна компанія планує вийти на нові ринки зі своїми існуючими продуктами (P1, P2, P3, P4 і P5). Після інтенсивного маркетингового дослідження вони дійшли висновку, що поведінка нового ринку схожа на їхній існуючий ринок.\n",
    "\n",
    "На своєму існуючому ринку команда з продажу класифікувала всіх клієнтів на 4 сегменти (A, B, C, D). Потім вони здійснювали сегментовані звернення та комунікацію з різними сегментами клієнтів. Ця стратегія працювала для них надзвичайно добре. Вони планують використати ту саму стратегію на нових ринках і визначили 2627 нових потенційних клієнтів.\n",
    "\n",
    "Ви маєте допомогти менеджеру передбачити правильну групу для нових клієнтів.\n",
    "\n",
    "В цьому ДЗ використовуємо дані `customer_segmentation_train.csv`[скачати дані](https://drive.google.com/file/d/1VU1y2EwaHkVfr5RZ1U4MPWjeflAusK3w/view?usp=sharing). Це `train.csv`з цього [змагання](https://www.kaggle.com/datasets/abisheksudarshan/customer-segmentation/data?select=train.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NZFXPKx1JX-3"
   },
   "source": [
    "**Завдання 1.** Завантажте та підготуйте датасет до аналізу. Виконайте обробку пропущених значень та необхідне кодування категоріальних ознак. Розбийте на тренувальну і тестувальну вибірку, де в тесті 20%. Памʼятаємо, що весь препроцесинг ліпше все ж тренувати на тренувальній вибірці і на тестувальній лише використовувати вже натреновані трансформери.\n",
    "Але в даному випадку оскільки значень в категоріях небагато, можна зробити обробку і на оригінальних даних, а потім розбити - це простіше. Можна також реалізувати процесинг і тренування моделі з пайплайнами. Обирайте як вам зручніше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "I-mwGqPS5GAT"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv('customer_segmentation_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = raw_df.dropna() \n",
    "raw_df.drop(columns=['ID'], inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(raw_df, test_size=0.2, random_state=42, stratify=raw_df['Segmentation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col_name = 'Segmentation'\n",
    "y = train_df[target_col_name]\n",
    "X = train_df.drop(columns=target_col_name)\n",
    "\n",
    "y_test = train_df[target_col_name]\n",
    "X_test = train_df.drop(columns=target_col_name)\n",
    "\n",
    "# Identifying numeric and categorical columns\n",
    "numeric_cols = X.select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_cols = X.select_dtypes(include='object').columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(drop='if_binary',sparse_output=False, handle_unknown='ignore')\n",
    "encoder.fit(X[categorical_cols].astype(str))\n",
    "\n",
    "encoded_cols = list(encoder.get_feature_names_out(categorical_cols))\n",
    "X[encoded_cols] = encoder.transform(X[categorical_cols].astype(str))\n",
    "X_test[encoded_cols] = encoder.transform(X_test[categorical_cols].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[numeric_cols+encoded_cols]\n",
    "X_val = X_test[numeric_cols+encoded_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fhJzCBA7P0f8"
   },
   "source": [
    "**Завдання 2. Важливо уважно прочитати все формулювання цього завдання до кінця!**\n",
    "\n",
    "Застосуйте методи ресемплингу даних SMOTE та SMOTE-Tomek з бібліотеки imbalanced-learn до тренувальної вибірки. В результаті у Вас має вийти 2 тренувальних набори: з апсемплингом зі SMOTE, та з ресамплингом з SMOTE-Tomek.\n",
    "\n",
    "Увага! В нашому наборі даних є як категоріальні дані, так і звичайні числові. Базовий SMOTE не буде правильно працювати з категоріальними даними, але є його модифікація, яка буде. Тому в цього завдання є 2 виконання\n",
    "\n",
    "  1. Застосувати SMOTE базовий лише на НЕкатегоріальних ознаках.\n",
    "\n",
    "  2. Переглянути інформацію про метод [SMOTENC](https://imbalanced-learn.org/dev/references/generated/imblearn.over_sampling.SMOTENC.html#imblearn.over_sampling.SMOTENC) і використати цей метод в цій задачі. За цей спосіб буде +3 бали за це завдання і він рекомендований для виконання.\n",
    "\n",
    "  **Підказка**: аби скористатись SMOTENC треба створити змінну, яка містить індекси ознак, які є категоріальними (їх номер серед колонок) і передати при ініціації екземпляра класу `SMOTENC(..., categorical_features=cat_feature_indeces)`.\n",
    "  \n",
    "  Ви також можете розглянути варіант використання варіації SMOTE, який працює ЛИШЕ з категоріальними ознаками [SMOTEN](https://imbalanced-learn.org/dev/references/generated/imblearn.over_sampling.SMOTEN.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "6NFUkQ_15HNX"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Perform random sampling\n",
    "smote = SMOTE(random_state=0)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train.select_dtypes(include=np.number), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTENC\n",
    "\n",
    "categorical_columns = X.select_dtypes(include=['object', 'category']).columns\n",
    "# Get indices of categorical columns\n",
    "cat_feature_indices = [X.columns.get_loc(col) for col in categorical_columns]\n",
    "X = X.apply(lambda col: col.astype(str) if col.dtype == 'object' else col)\n",
    "\n",
    "sm = SMOTENC(random_state=0, categorical_features=cat_feature_indices)\n",
    "X_train_smotenc, y_train_smotenc = sm.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "smotetomek = SMOTETomek(random_state=0)\n",
    "X_train_smotetomek, y_train_smotetomek = smotetomek.fit_resample(X_train.select_dtypes(include=np.number), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ja4w_GgmT4D0"
   },
   "source": [
    "**Завдання 3**.\n",
    "  1. Навчіть модель логістичної регресії з використанням стратегії One-vs-Rest з логістичною регресією на оригінальних даних, збалансованих з SMOTE, збалансованих з Smote-Tomek.  \n",
    "  2. Виміряйте якість кожної з натренованих моделей використовуючи `sklearn.metrics.classification_report`.\n",
    "  3. Напишіть, яку метрику ви обрали для порівняння моделей.\n",
    "  4. Яка модель найкраща?\n",
    "  5. Якщо немає суттєвої різниці між моделями - напишіть свою гіпотезу, чому?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Ever_Married_Yes</th>\n",
       "      <th>Graduated_Yes</th>\n",
       "      <th>Profession_Artist</th>\n",
       "      <th>Profession_Doctor</th>\n",
       "      <th>Profession_Engineer</th>\n",
       "      <th>Profession_Entertainment</th>\n",
       "      <th>...</th>\n",
       "      <th>Spending_Score_Average</th>\n",
       "      <th>Spending_Score_High</th>\n",
       "      <th>Spending_Score_Low</th>\n",
       "      <th>Var_1_Cat_1</th>\n",
       "      <th>Var_1_Cat_2</th>\n",
       "      <th>Var_1_Cat_3</th>\n",
       "      <th>Var_1_Cat_4</th>\n",
       "      <th>Var_1_Cat_5</th>\n",
       "      <th>Var_1_Cat_6</th>\n",
       "      <th>Var_1_Cat_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2339</th>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3124</th>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3647</th>\n",
       "      <td>36</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3703</th>\n",
       "      <td>60</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2124</th>\n",
       "      <td>52</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749</th>\n",
       "      <td>49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2878</th>\n",
       "      <td>26</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5332 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  Work_Experience  Family_Size  Gender_Male  Ever_Married_Yes  \\\n",
       "2339   18              1.0          5.0          0.0               0.0   \n",
       "3124   25              0.0          3.0          0.0               0.0   \n",
       "3647   36              9.0          3.0          1.0               0.0   \n",
       "3703   60              3.0          2.0          1.0               1.0   \n",
       "667    69              0.0          3.0          1.0               1.0   \n",
       "...   ...              ...          ...          ...               ...   \n",
       "2124   52              6.0          2.0          0.0               1.0   \n",
       "1438   49              0.0          2.0          1.0               1.0   \n",
       "1749   49              1.0          4.0          1.0               1.0   \n",
       "1560   38              0.0          4.0          1.0               1.0   \n",
       "2878   26             10.0          1.0          1.0               0.0   \n",
       "\n",
       "      Graduated_Yes  Profession_Artist  Profession_Doctor  \\\n",
       "2339            0.0                0.0                0.0   \n",
       "3124            0.0                0.0                1.0   \n",
       "3647            1.0                0.0                0.0   \n",
       "3703            1.0                1.0                0.0   \n",
       "667             1.0                1.0                0.0   \n",
       "...             ...                ...                ...   \n",
       "2124            1.0                1.0                0.0   \n",
       "1438            0.0                1.0                0.0   \n",
       "1749            1.0                1.0                0.0   \n",
       "1560            0.0                0.0                0.0   \n",
       "2878            1.0                0.0                0.0   \n",
       "\n",
       "      Profession_Engineer  Profession_Entertainment  ...  \\\n",
       "2339                  0.0                       1.0  ...   \n",
       "3124                  0.0                       0.0  ...   \n",
       "3647                  0.0                       0.0  ...   \n",
       "3703                  0.0                       0.0  ...   \n",
       "667                   0.0                       0.0  ...   \n",
       "...                   ...                       ...  ...   \n",
       "2124                  0.0                       0.0  ...   \n",
       "1438                  0.0                       0.0  ...   \n",
       "1749                  0.0                       0.0  ...   \n",
       "1560                  0.0                       0.0  ...   \n",
       "2878                  0.0                       0.0  ...   \n",
       "\n",
       "      Spending_Score_Average  Spending_Score_High  Spending_Score_Low  \\\n",
       "2339                     0.0                  0.0                 1.0   \n",
       "3124                     0.0                  0.0                 1.0   \n",
       "3647                     0.0                  0.0                 1.0   \n",
       "3703                     1.0                  0.0                 0.0   \n",
       "667                      1.0                  0.0                 0.0   \n",
       "...                      ...                  ...                 ...   \n",
       "2124                     0.0                  0.0                 1.0   \n",
       "1438                     0.0                  0.0                 1.0   \n",
       "1749                     1.0                  0.0                 0.0   \n",
       "1560                     0.0                  1.0                 0.0   \n",
       "2878                     0.0                  0.0                 1.0   \n",
       "\n",
       "      Var_1_Cat_1  Var_1_Cat_2  Var_1_Cat_3  Var_1_Cat_4  Var_1_Cat_5  \\\n",
       "2339          0.0          1.0          0.0          0.0          0.0   \n",
       "3124          0.0          0.0          0.0          0.0          0.0   \n",
       "3647          0.0          0.0          0.0          0.0          0.0   \n",
       "3703          0.0          0.0          0.0          0.0          0.0   \n",
       "667           0.0          0.0          0.0          0.0          0.0   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "2124          0.0          0.0          0.0          0.0          0.0   \n",
       "1438          0.0          0.0          0.0          0.0          0.0   \n",
       "1749          0.0          0.0          0.0          0.0          0.0   \n",
       "1560          0.0          0.0          0.0          0.0          0.0   \n",
       "2878          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "      Var_1_Cat_6  Var_1_Cat_7  \n",
       "2339          0.0          0.0  \n",
       "3124          1.0          0.0  \n",
       "3647          1.0          0.0  \n",
       "3703          1.0          0.0  \n",
       "667           1.0          0.0  \n",
       "...           ...          ...  \n",
       "2124          1.0          0.0  \n",
       "1438          0.0          1.0  \n",
       "1749          1.0          0.0  \n",
       "1560          0.0          1.0  \n",
       "2878          1.0          0.0  \n",
       "\n",
       "[5332 rows x 25 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.43      0.49      0.46      1293\n",
      "           B       0.42      0.18      0.25      1257\n",
      "           C       0.51      0.67      0.58      1376\n",
      "           D       0.65      0.71      0.68      1406\n",
      "\n",
      "    accuracy                           0.52      5332\n",
      "   macro avg       0.50      0.51      0.49      5332\n",
      "weighted avg       0.51      0.52      0.50      5332\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.43      0.49      0.46      1293\n",
      "           B       0.42      0.18      0.25      1257\n",
      "           C       0.51      0.67      0.58      1376\n",
      "           D       0.65      0.71      0.68      1406\n",
      "\n",
      "    accuracy                           0.52      5332\n",
      "   macro avg       0.50      0.51      0.49      5332\n",
      "weighted avg       0.51      0.52      0.50      5332\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "ovr_model = OneVsRestClassifier(model)\n",
    "ovr_model.fit(X_train, y)\n",
    "ovr_predictions_test = ovr_model.predict(X_test.select_dtypes(include=np.number))\n",
    "ovr_predictions_train = ovr_model.predict(X_train.select_dtypes(include=np.number))\n",
    "\n",
    "print(classification_report(y_test, ovr_predictions_test))\n",
    "print(classification_report(y, ovr_predictions_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "nxWVeRan5JBh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.43      0.50      0.46      1293\n",
      "           B       0.42      0.25      0.31      1257\n",
      "           C       0.54      0.63      0.58      1376\n",
      "           D       0.66      0.68      0.67      1406\n",
      "\n",
      "    accuracy                           0.52      5332\n",
      "   macro avg       0.51      0.51      0.51      5332\n",
      "weighted avg       0.51      0.52      0.51      5332\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model_smote = LogisticRegression(solver='liblinear')\n",
    "ovr_model_smote = OneVsRestClassifier(model_smote)\n",
    "ovr_model_smote.fit(X_train_smote, y_train_smote)\n",
    "ovr_predictions_smote_test = ovr_model_smote.predict(X_test.select_dtypes(include=np.number))\n",
    "\n",
    "print(classification_report(y_test, ovr_predictions_smote_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.42      0.51      0.46      1293\n",
      "           B       0.42      0.24      0.31      1257\n",
      "           C       0.54      0.62      0.58      1376\n",
      "           D       0.66      0.68      0.67      1406\n",
      "\n",
      "    accuracy                           0.52      5332\n",
      "   macro avg       0.51      0.51      0.50      5332\n",
      "weighted avg       0.51      0.52      0.51      5332\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_smotenc = LogisticRegression(solver='liblinear')\n",
    "ovr_model_smotenc = OneVsRestClassifier(model_smotenc)\n",
    "ovr_model_smotenc.fit(X_train_smotenc[numeric_cols+encoded_cols], y_train_smotenc)\n",
    "ovr_predictions_smotenc = ovr_model_smotenc.predict(X_test[numeric_cols+encoded_cols])\n",
    "\n",
    "print(classification_report(y_test, ovr_predictions_smotenc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.43      0.51      0.47      1293\n",
      "           B       0.43      0.25      0.31      1257\n",
      "           C       0.54      0.64      0.58      1376\n",
      "           D       0.66      0.68      0.67      1406\n",
      "\n",
      "    accuracy                           0.52      5332\n",
      "   macro avg       0.51      0.52      0.51      5332\n",
      "weighted avg       0.52      0.52      0.51      5332\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_smotetomek = LogisticRegression(solver='liblinear')\n",
    "ovr_model_smotetomek = OneVsRestClassifier(model_smotetomek)\n",
    "ovr_model_smotetomek.fit(X_train_smotetomek[numeric_cols+encoded_cols], y_train_smotetomek)\n",
    "ovr_predictions_smotetomek = ovr_model_smotetomek.predict(X_test[numeric_cols+encoded_cols])\n",
    "\n",
    "print(classification_report(y_test, ovr_predictions_smotetomek))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Conclusion\n",
    "\n",
    "All models perform similarly in terms of accuracy (~52%), macro-average F1-score (~0.50-0.51), and weighted-average F1-score (~0.50-0.51). Probably due to initial balanced sampling.\n",
    "\n",
    "However, SMOTE-Tomek balancing is slightly better because it achieves the highest macro-average F1-score (0.51) and improves recall across all classes without sacrificing precision. It provides a more balanced classification performance, particularly benefiting underrepresented classes.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "102QTrQmOuzlHneyojj2gM-8U9dJN_hCH",
     "timestamp": 1737290641653
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
